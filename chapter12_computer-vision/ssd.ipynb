{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单发多框检测（SSD）\n",
    "## 模型\n",
    "\n",
    "下图描述了单发多框检测模型的设计。\n",
    "此模型主要由基础网络组成，其后是几个多尺度特征块。\n",
    "基本网络用于从输入图像中提取特征，因此它可以使用深度卷积神经网络。\n",
    "单发多框检测论文中选用了在分类层之前截断的VGG，现在也常用ResNet替代。\n",
    "我们可以设计基础网络，使它输出的高和宽较大。\n",
    "这样一来，基于该特征图生成的锚框数量较多，可以用来检测尺寸较小的目标。\n",
    "接下来的每个多尺度特征块将上一层提供的特征图的高和宽缩小（如减半），并使特征图中每个单元在输入图像上的感受野变得更广阔。\n",
    "\n",
    "由于接近下图顶部的多尺度特征图较小，但具有较大的感受野，它们适合检测较少但较大的物体。\n",
    "简而言之，通过多尺度特征块，单发多框检测生成不同大小的锚框，并通过预测边界框的类别和偏移量来检测大小不同的目标，因此这是一个多尺度目标检测模型。\n",
    "\n",
    "![单发多框检测模型主要由一个基础网络块和若干多尺度特征块串联而成。](../img/ssd.svg)\n",
    "\n",
    "在下面，我们将介绍上图中不同块的实施细节。\n",
    "首先，我们将讨论如何实施类别和边界框预测。\n",
    "\n",
    "### 类别预测层\n",
    "\n",
    "设目标类别的数量为$q$。这样一来，锚框有$q+1$个类别，其中0类是背景。\n",
    "在某个尺度下，设特征图的高和宽分别为$h$和$w$。\n",
    "如果以其中每个单元为中心生成$a$个锚框，那么我们需要对$hwa$个锚框进行分类。\n",
    "如果使用全连接层作为输出，很容易导致模型参数过多。\n",
    "单发多框检测就是采用卷积层的通道来输出类别预测的方法来降低模型复杂度。\n",
    "\n",
    "具体来说，类别预测层使用一个保持输入高和宽的卷积层。\n",
    "这样一来，输出和输入在特征图宽和高上的空间坐标一一对应。\n",
    "考虑输出和输入同一空间坐标（$x$、$y$）：输出特征图上（$x$、$y$）坐标的通道里包含了以输入特征图（$x$、$y$）坐标为中心生成的所有锚框的类别预测。\n",
    "因此输出通道数为$a(q+1)$，其中索引为$i(q+1) + j$（$0 \\leq j \\leq q$）的通道代表了索引为$i$的锚框有关类别索引为$j$的预测。\n",
    "\n",
    "在下面，我们定义了这样一个类别预测层，通过参数`num_anchors`和`num_classes`分别指定了$a$和$q$。\n",
    "该图层使用填充为1的$3\\times3$的卷积层。此卷积层的输入和输出的宽度和高度保持不变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 类别预测\n",
    "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
    "    \"\"\"\n",
    "    num_inputs: 输入通道数\n",
    "    num_anchors: 每个单元为中心生成的锚框数\n",
    "    num_classes: 目标类别的数量\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(num_inputs, num_anchors*(num_classes + 1), kernel_size=3, padding=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 边界框预测层\n",
    "边界框预测层的设计与类别预测层的设计类似。\n",
    "唯一不同的是，这里需要为每个锚框预测4个偏移量，而不是$q+1$个类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边界框预测\n",
    "def bbox_predictor(num_inputs, num_anchors):\n",
    "    \"\"\"\n",
    "    num_inputs: 输入通道数\n",
    "    num_anchors: 每个单元为中心生成的锚框数\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连结多尺度的预测\n",
    "正如我们所提到的，单发多框检测使用多尺度特征图来生成锚框并预测其类别和偏移量。\n",
    "在不同的尺度下，特征图的形状或以同一单元为中心的锚框的数量可能会有所不同。\n",
    "因此，不同尺度下预测输出的形状可能会有所不同。\n",
    "\n",
    "在以下示例中，我们为同一个小批量构建两个不同比例（`Y1`和`Y2`）的特征图，其中`Y2`的高度和宽度是`Y1`的一半。\n",
    "以类别预测为例，假设`Y1`和`Y2`的每个单元分别生成了$5$个和$3$个锚框。\n",
    "进一步假设目标类别的数量为$10$，对于特征图`Y1`和`Y2`，类别预测输出中的通道数分别为$5\\times(10+1)=55$和$3\\times(10+1)=33$，其中任一输出的形状是（批量大小，通道数，高度，宽度）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, block):\n",
    "    return block(x)\n",
    "\n",
    "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
    "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
    "Y1.shape, Y2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们所看到的，除了批量大小这一维度外，其他三个维度都具有不同的尺寸。\n",
    "为了将这两个预测输出链接起来以提高计算效率，我们将把这些张量转换为更一致的格式。\n",
    "\n",
    "通道维包含中心相同的锚框的预测结果。我们首先将通道维移到最后一维。\n",
    "因为不同尺度下批量大小仍保持不变，我们可以将预测结果转成二维的（批量大小，高$\\times$宽$\\times$通道数）的格式，以方便之后在维度$1$上的连结。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将输入的张量进行维度转换和展平操作\n",
    "def flaten_pred(pred):\n",
    "    # 首先使用 permute 函数将通道维度移动到最后一个维度，\n",
    "    # 然后使用 flatten 函数将张量展平为一维\n",
    "    return torch.flatten(pred.permute(0,2,3,1), start_dim=1)\n",
    "\n",
    "# 将多个张量拼接在一起\n",
    "def concat_preds(preds):\n",
    "    # 使用列表推导式和 torch.cat 函数将输入列表中的每个张量展平后进行拼接\n",
    "    return torch.cat([flaten_pred(p) for p in preds], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样一来，尽管Y1和Y2在通道数、高度和宽度方面具有不同的大小，我们仍然可以在同一个小批量的两个不同尺度上连接这两个预测输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25300])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_preds([Y1, Y2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高宽减半块\n",
    "为了在多个尺度下检测目标，我们在下面定义了高和宽减半块`down_sample_blk`，该模块将输入特征图的高度和宽度减半。\n",
    "事实上，该块应用了VGG模块设计。\n",
    "更具体地说，每个高和宽减半块由两个填充为$1$的$3\\times3$的卷积层、以及步幅为$2$的$2\\times2$最大汇聚层组成。\n",
    "我们知道，填充为$1$的$3\\times3$卷积层不改变特征图的形状。但是，其后的$2\\times2$的最大汇聚层将输入特征图的高度和宽度减少了一半。\n",
    "对于此高和宽减半块的输入和输出特征图，因为$1\\times 2+(3-1)+(3-1)=6$，所以输出中的每个单元在输入上都有一个$6\\times6$的感受野。因此，高和宽减半块会扩大每个单元在其输出特征图中的感受野。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个包含卷积层、批归一化层和ReLU激活函数的序列\n",
    "def down_sample_blk(in_channels, out_channels):\n",
    "    \"\"\"\n",
    "    in_channels: 输入通道数\n",
    "    out_channels: 输出通道数\n",
    "    \"\"\"\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.BatchNorm2d(out_channels))\n",
    "        blk.append(nn.ReLU())\n",
    "        # 在下一次循环中使用新的in_channels值\n",
    "        in_channels = out_channels\n",
    "    blk.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在以下示例中，我们构建的高和宽减半块会更改输入通道的数量，并将输入特征图的高度和宽度减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(torch.zeros((2,3,20,20)), down_sample_blk(3,10)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本网络块\n",
    "基本网络块用于从输入图像中抽取特征。\n",
    "为了计算简洁，我们构造了一个小的基础网络，该网络串联3个高和宽减半块，并逐步将通道数翻倍。\n",
    "给定输入图像的形状为$256\\times256$，此基本网络块输出的特征图形状为$32 \\times 32$（$256/2^3=32$）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_net():\n",
    "    blk = []\n",
    "    num_filters = [3,16,32,64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "forward(torch.zeros((2,3,256,256)), base_net()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整的模型\n",
    "完整的单发多框检测模型由五个模块组成。每个块生成的特征图既用于生成锚框，又用于预测这些锚框的类别和偏移量。在这五个模块中，第一个是基本网络块，第二个到第四个是高和宽减半块，最后一个模块使用全局最大池将高度和宽度都降到1。从技术上讲，第二到第五个区块都是多尺度特征块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 1:\n",
    "        blk = down_sample_blk(64, 128)\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d((1,1))\n",
    "    else:\n",
    "        blk = down_sample_blk(128, 128)\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们为每个块定义前向传播。与图像分类任务不同，此处的输出包括：CNN特征图`Y`；在当前尺度下根据`Y`生成的锚框；预测的这些锚框的类别和偏移量（基于`Y`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将输入数据通过块函数进行处理，然后生成锚框，并使用类别预测模型和边界框预测模型对生成的特征图进行预测。\n",
    "# 最后，函数返回处理后的特征图、锚框的位置、类别预测结果和边界框预测结果\n",
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    \"\"\"\n",
    "    X: 输入数据\n",
    "    blk: 一个用于处理输入数据的块（block）函数\n",
    "    size: 一个包含不同尺寸的锚框（anchor box）的列表\n",
    "    ratio: 一个包含不同宽高比的锚框的列表\n",
    "    cls_predictor: 用于预测类别的模型\n",
    "    bbox_predictor: 用于预测边界框的模型\n",
    "    \"\"\"\n",
    "\n",
    "    Y = blk(X)\n",
    "    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)\n",
    "    cls_predictor = cls_predictor(Y)\n",
    "    bbox_predictor = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_predictor, bbox_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个较接近顶部的多尺度特征块是用于检测较大目标的，因此需要生成更大的锚框。\n",
    "在上面的前向传播中，在每个多尺度特征块上，我们通过调用的`multibox_prior`函数的`sizes`参数传递两个比例值的列表。\n",
    "在下面，0.2和1.05之间的区间被均匀分成五个部分，以确定五个模块的在不同尺度下的较小值：0.2、0.37、0.54、0.71和0.88。\n",
    "之后，他们较大的值由$\\sqrt{0.2 \\times 0.37} = 0.272$、$\\sqrt{0.37 \\times 0.54} = 0.447$等给出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "         [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们就可以按如下方式定义完整的模型TinySSD了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySSD(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "        num_classes: 类别数量\n",
    "        **kwargs: 一个特殊的参数，它允许函数接受任意数量的关键字参数\n",
    "        \"\"\"\n",
    "        super(TinySSD, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        idx_to_in_channels = [64, 128, 128, 128, 128]\n",
    "        for i in range(5):\n",
    "            setattr(self, f'blk_{i}', get_blk(i))\n",
    "            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i], num_anchors, num_classes))\n",
    "            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i], num_anchors))\n",
    "\n",
    "    def forward(self, X):\n",
    "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
    "        for i in range(5):\n",
    "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(\n",
    "                X, getattr(self, f'blk_{i}'),sizes[i], ratios[i], \n",
    "                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))\n",
    "        anchors = torch.cat(anchors, dim=1)\n",
    "        cls_preds = concat_preds(cls_preds)\n",
    "        # 将cls_preds的形状重新调整为(batch_size, -1, num_classes + 1)。\n",
    "        # 其中，batch_size表示批量大小，num_classes表示类别数量。\n",
    "        # 这样做的目的是将每个样本的预测结果按照类别进行排列，方便后续处理和计算\n",
    "        cls_preds = cls_preds.reshape(cls_preds.shape[0], -1, self.num_classes + 1)\n",
    "        bbox_preds = concat_preds(bbox_preds)\n",
    "        return anchors, cls_preds, bbox_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们创建一个模型实例，然后使用它对一个$256 \\times 256$像素的小批量图像`X`执行前向传播。\n",
    "\n",
    "如前面部分所示，第一个模块输出特征图的形状为$32 \\times 32$。\n",
    "回想一下，第二到第四个模块为高和宽减半块，第五个模块为全局汇聚层。\n",
    "由于以特征图的每个单元为中心有$4$个锚框生成，因此在所有五个尺度下，每个图像总共生成$(32^2 + 16^2 + 8^2 + 4^2 + 1)\\times 4 = 5444$个锚框。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output anchors: torch.Size([1, 5444, 4])\n",
      "output class preds: torch.Size([32, 5444, 2])\n",
      "output bbox preds: torch.Size([32, 21776])\n"
     ]
    }
   ],
   "source": [
    "net = TinySSD(num_classes=1)\n",
    "X = torch.zeros((32,3,256,256))\n",
    "anchors, cls_preds, bbox_preds = net(X)\n",
    "\n",
    "print('output anchors:', anchors.shape)\n",
    "print('output class preds:', cls_preds.shape)\n",
    "print('output bbox preds:', bbox_preds.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
